# LLM Provider Configuration
# AgentVerse supports both Ollama (local) and OpenAI (cloud)
# It will try Ollama first, then fallback to OpenAI if needed

# Ollama Configuration (Local AI)
USE_OLLAMA=true
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2
# Other good models: mistral, codellama, neural-chat, phi

# OpenAI Configuration (Cloud AI)
OPENAI_API_KEY=your_openai_api_key_here

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Optional: Database Configuration
# DATABASE_URL=postgresql://user:password@localhost/agentverse

# Optional: Redis Configuration (for caching)
# REDIS_URL=redis://localhost:6379

# Optional: Advanced Settings
# OPENAI_MODEL=gpt-4o-mini
# OPENAI_MAX_TOKENS=1000
# OPENAI_TEMPERATURE=0.7